p8105_hw2_ww2744
================
Wenjie Wu

# Problem 1

Import the NYC Transit data

``` r
trans_df = 
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c("NA", "",".")) |>
  janitor::clean_names() |>
  select(line:entry, vending, ada) |>
  mutate(
    entry = case_match(
      entry,
      "YES" ~ TRUE,
      "NO" ~ FALSE
    )
  )
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

- The dataset contains 1863 rows and 19 columns.
- This dataset contains information about subway entrances and exits in
  New York City. Key variables include the subway line, station name,
  station latitude/longitude, routes served, entry (whether the entrance
  allows entry), vending, entrance type (e.g., stairs, escalator), and
  ADA compliance.

Cleaning steps:

- Load data, take `NA` vaules like: “NA”, ““,”.” as missing values.
- Use janitor::clean_names() to transform all the col names into letters
- Use `select` function to select the columns needed to be anaylzed.
- Use `case_match` to convert `entry` variable to a logical variable.

``` r
distinct_stations = trans_df |>
  distinct(line, station_name) |>
  nrow() |>
  print()
```

    ## [1] 465

- There are `distinct_stations` distinct stations.

``` r
ada_compliant_stations = trans_df |>
  filter(ada == TRUE) |>
  distinct(line, station_name) |>
  nrow() |>
  print()
```

    ## [1] 84

- 84 stations are ADA compliant.

``` r
proportion_non_vending_allow_entry = trans_df |>
  filter(vending == "NO") |>
  summarise(proportion = mean(entry == TRUE, na.rm = TRUE)) |>
  unlist() |>
  percent() |>
  print()
```

    ## proportion 
    ##      "38%"

- About 38% of station entrances/exits without vending machines allow
  entrance.

``` r
tidy_data = trans_df |>
  mutate(across(starts_with("Route"), as.character)) |>
  pivot_longer(cols = starts_with("route"), 
               names_to = "route_Number", 
               values_to = "route_Name", 
               values_drop_na = TRUE)

stations_serving_A = tidy_data |>
  filter(route_Name == "A") |>
  distinct(line, station_name) |>
  nrow()|>
  print()
```

    ## [1] 60

``` r
ada_compliant_stations_A = tidy_data |>
  filter(route_Name == "A" & ada == TRUE) |>
  distinct(line, station_name) |>
  nrow() |>
  print()
```

    ## [1] 17

- 60 distinct stations serve the A train.
- Among them 17 are ADA compliant.

# Problem 2

Read and clean the data

Mr. Trash Wheel

``` r
Trash_wheel = 
  read_excel(
    "data/202309 Trash Wheel Collection Data.xlsx", 
    sheet = "Mr. Trash Wheel",
    skip = 1,
    na = c("NA", ",", ".")
  ) |>
  select(-c(...15, ...16)) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(
    sports_balls = as.integer(round(sports_balls))
  )
```

Load Professor Trash Wheel and Gwynnda

``` r
Professor_trash_wheel = 
  read_excel(
    "data/202309 Trash Wheel Collection Data.xlsx", 
    sheet = "Professor Trash Wheel",
    skip = 1,
    na = c("NA", ",", ".")
  ) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster))
  

Gwynnda_trash_wheel = 
    read_excel(
    "data/202309 Trash Wheel Collection Data.xlsx", 
    sheet = "Gwynnda Trash Wheel",
    skip = 1,
    na = c("NA", ",", ".")
  ) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster))
```

Combine the datasets

``` r
Trash_wheel = Trash_wheel |> mutate(trash_wheel = "Mr. Trash Wheel",
                      year = as.character(year))
Professor_trash_wheel = Professor_trash_wheel |> mutate(trash_wheel = "Professor Trash Wheel",
                                year = as.character(year))
Gwynnda_trash_wheel = Gwynnda_trash_wheel|>  mutate(trash_wheel = "Gwynnda Trash Wheel",
                              year = as.character(year))


combined_trash_wheel = bind_rows(Trash_wheel, Professor_trash_wheel, Gwynnda_trash_wheel) |>
  select(-c(dumpster)) |>
  relocate(trash_wheel)
```

- The combined dataset of trash collected by Mr. Trash Wheel, Professor
  Trash Wheel, and Gwynnda Trash Wheel contains 845 observations.
- Key variables include weight_tons representing the weight of trash
  collected per dumpster, the time of collection and specific waste
  types like plastic_bottles and cigarette_butts.

``` r
total_weight_prof = sum(
  filter(combined_trash_wheel, trash_wheel == "Professor Trash Wheel") |>
    select(weight_tons),
  na.rm = TRUE
)
total_weight_gwy = sum(
  filter(combined_trash_wheel, trash_wheel == "Professor Trash Wheel" & month == "June" & year == "2022" ) |>
    select(cigarette_butts), 
    na.rm = TRUE
)
```

- For Professor Trash Wheel, the total weight of trash collected is
  216.26 tons. Meanwhile, Gwynnda Trash Wheel collected
  1.16^{4}cigarette butts in June of 2022.

# Problem 3

Import and clean datasets

``` r
bakers_df =   read_csv("data/gbb_datasets/bakers.csv", na = c("NA", "",".")) |>
  janitor::clean_names() |>
  separate(col = baker_name, into = c("baker", "baker_last_name"), sep = " ") |>
  print()
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

    ## # A tibble: 120 × 6
    ##    baker     baker_last_name series baker_age baker_occupation          hometown
    ##    <chr>     <chr>            <dbl>     <dbl> <chr>                     <chr>   
    ##  1 Ali       Imdad                4        25 Charity worker            Saltley…
    ##  2 Alice     Fevronia            10        28 Geography teacher         Essex   
    ##  3 Alvin     Magallanes           6        37 Nurse                     Brackne…
    ##  4 Amelia    LeBruin             10        24 Fashion designer          Halifax 
    ##  5 Andrew    Smyth                7        25 Aerospace engineer        Derby /…
    ##  6 Annetha   Mills                1        30 Midwife                   Essex   
    ##  7 Antony    Amourdoux            9        30 Banker                    London  
    ##  8 Beca      Lyne-Pirkis          4        31 Military Wives' Choir Si… Aldersh…
    ##  9 Ben       Frazer               2        31 Graphic Designer          Northam…
    ## 10 Benjamina Ebuehi               7        23 Teaching assistant        South L…
    ## # ℹ 110 more rows

``` r
bakes_df = read_csv("data/gbb_datasets/bakes.csv", na = c("NA", "",".", "N/A")) |>
  janitor::clean_names() |>
  mutate(baker = ifelse(baker == '"Jo"', "Joanne", baker)) |>
  print()
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

    ## # A tibble: 548 × 5
    ##    series episode baker     signature_bake                          show_stopper
    ##     <dbl>   <dbl> <chr>     <chr>                                   <chr>       
    ##  1      1       1 Annetha   "Light Jamaican Black Cakewith Strawbe… Red, White …
    ##  2      1       1 David     "Chocolate Orange Cake"                 Black Fores…
    ##  3      1       1 Edd       "Caramel Cinnamon and Banana Cake"      <NA>        
    ##  4      1       1 Jasminder "Fresh Mango and Passion Fruit Humming… <NA>        
    ##  5      1       1 Jonathan  "Carrot Cake with Lime and Cream Chees… Three Tiere…
    ##  6      1       1 Lea       "Cranberry and Pistachio Cakewith Oran… Raspberries…
    ##  7      1       1 Louise    "Carrot and Orange Cake"                Never Fail …
    ##  8      1       1 Mark      "Sticky Marmalade Tea Loaf"             Heart-shape…
    ##  9      1       1 Miranda   "Triple Layered Brownie Meringue Cake\… Three Tiere…
    ## 10      1       1 Ruth      "Three Tiered Lemon Drizzle Cakewith F… Classic Cho…
    ## # ℹ 538 more rows

``` r
results_df = read_csv("data/gbb_datasets/results.csv", na = c("NA", "","."), skip = 2) |>
  janitor::clean_names() |>
  print()
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

    ## # A tibble: 1,136 × 5
    ##    series episode baker     technical result
    ##     <dbl>   <dbl> <chr>         <dbl> <chr> 
    ##  1      1       1 Annetha           2 IN    
    ##  2      1       1 David             3 IN    
    ##  3      1       1 Edd               1 IN    
    ##  4      1       1 Jasminder        NA IN    
    ##  5      1       1 Jonathan          9 IN    
    ##  6      1       1 Louise           NA IN    
    ##  7      1       1 Miranda           8 IN    
    ##  8      1       1 Ruth             NA IN    
    ##  9      1       1 Lea              10 OUT   
    ## 10      1       1 Mark             NA OUT   
    ## # ℹ 1,126 more rows

``` r
viewers_df = read_csv("data/gbb_datasets/viewers.csv", na = c("NA", "",".")) |>
  janitor::clean_names() |>
  pivot_longer(
    cols = series_1:series_10,
    names_to = "series",
    values_to = "viewers",
    names_prefix = "series_"
  )
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Check for completeness and correctness

``` r
missing_in_bakes = anti_join(bakers_df, bakes_df, 
                              by = c("baker" = "baker", "series"))

missing_in_results = anti_join(bakers_df, results_df, 
                                by = c("baker" = "baker", "series"))

missing_in_results_for_bakes = anti_join(bakes_df, results_df, 
                                          by = c("baker", "series", "episode"))
```

Create a single dataset

``` r
GBBF_df = left_join(results_df, bakes_df, by = c("series", "episode", "baker")) |>
  left_join(bakers_df, by = c("series", "baker")) |>
  relocate(series, episode, baker, baker_last_name, baker_age, baker_occupation, hometown, signature_bake, technical, result, show_stopper)

write.csv(GBBF_df, file = "data/gbb_datasets/GBBF.csv", row.names = FALSE)
```
